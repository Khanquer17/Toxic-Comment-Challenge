{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "2281f47f-c3c0-4125-ad52-740fcc57d509",
    "_uuid": "11c94e23b16ac6d7a23e5066251b8dbd8f9d7ea4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "79cefcba-f248-4e04-992c-0b56f07ef520",
    "_uuid": "e0a729a5e4b680ae956dd33fc20c13d1ce5ab83f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "c1b2f9b7-d5ce-4518-8296-e5224920d658",
    "_uuid": "b809d3b9bbb2594b2b9bafd6ae16efabe08df43d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "9af92c8b-dd04-4240-88dc-db5dcfd5e8b5",
    "_uuid": "823102e0efa9ecb5daa8a339acfae8e75e5fc39e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None,max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "3ac541ac-8cb0-43d1-94f8-923e42f90fd7",
    "_uuid": "4aab8b4ae5782744628a3f13e8ced9c7e82fc9bd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [clean_text],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "ac229cf5c667bf0bef122a8c4e2a63ce1c6510d7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_hyper_parm_logi = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "target = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "44a39a6f-a547-4ed4-b1f3-cc9fa6b45d7d",
    "_uuid": "638aec883cbdf9d8ea3d8cd634c78d786e6255ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".............. Started model fitting for toxic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed: 14.1min remaining:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............. Completed model fitting for toxic\n",
      "\n",
      "Best paramters for toxic\n",
      "\n",
      ".............. Completed model Prediction for toxic\n",
      "\n",
      ".............. Started model fitting for severe_toxic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed: 16.6min remaining:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 16.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............. Completed model fitting for severe_toxic\n",
      "\n",
      "Best paramters for severe_toxic\n",
      "\n",
      ".............. Completed model Prediction for severe_toxic\n",
      "\n",
      ".............. Started model fitting for obscene\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed: 16.9min remaining:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 17.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............. Completed model fitting for obscene\n",
      "\n",
      "Best paramters for obscene\n",
      "\n",
      ".............. Completed model Prediction for obscene\n",
      "\n",
      ".............. Started model fitting for threat\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed: 20.3min remaining:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 20.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............. Completed model fitting for threat\n",
      "\n",
      "Best paramters for threat\n",
      "\n",
      ".............. Completed model Prediction for threat\n",
      "\n",
      ".............. Started model fitting for insult\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed: 15.1min remaining:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............. Completed model fitting for insult\n",
      "\n",
      "Best paramters for insult\n",
      "\n",
      ".............. Completed model Prediction for insult\n",
      "\n",
      ".............. Started model fitting for identity_hate\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed: 15.8min remaining:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............. Completed model fitting for identity_hate\n",
      "\n",
      "Best paramters for identity_hate\n",
      "\n",
      ".............. Completed model Prediction for identity_hate\n"
     ]
    }
   ],
   "source": [
    "for label in target:\n",
    "    print('')\n",
    "    print(\".............. Started model fitting for \"+ label)\n",
    "    gs_lr_tfidf.fit(train_df.comment_text.values, train_df[label].values)\n",
    "    print(\".............. Completed model fitting for \"+ label)\n",
    "    print('')\n",
    "    print(\"Best paramters for \"+label)\n",
    "    gs_lr_tfidf.best_params_\n",
    "    print('')\n",
    "    test_y_prob = gs_lr_tfidf.predict_proba(test_df.comment_text)[:,1]\n",
    "    submission_hyper_parm_logi[label] = test_y_prob\n",
    "    print(\".............. Completed model Prediction for \"+ label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b61544ba265e9ee67f403b4f91a5c909412cb0c5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission_hyper_parm_logi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f516a7c0f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission_hyper_parm_logi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission_hyper_parm_logi.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission_hyper_parm_logi' is not defined"
     ]
    }
   ],
   "source": [
    "submission_hyper_parm_logi.to_csv(\"submission_hyper_parm_logi.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ff1dc8205bf1e557661791162e553f6289976a9",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
